---
title: "CIS 2020 análisis"
subtitle: "Análisis de datos de todos los partidos"
author: "ImJaviPerez"
date: "Diciembre 2022"
output:
  html_document:
    toc: yes
    toc_depth: '4'
    df_print: paged
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
header-includes:
- \usepackage{xcolor}
- \usepackage{framed}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[RO,RE]{AnálisiS total}
- \fancyfoot{}
- \fancyfoot[RE,LO]{Votos 2020}
- \fancyfoot[LE,RO]{\thepage}
bibliography: BibliografiaME.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message = FALSE)

#    include = FALSE prevents code and results from appearing in the finished file. R Markdown still runs the code in the chunk, and the results can be used by other chunks.
#    echo = FALSE prevents code, but not the results from appearing in the finished file. This is a useful way to embed figures.
#    message = FALSE prevents messages that are generated by code from appearing in the finished file.
#    warning = FALSE prevents warnings that are generated by code from appearing in the finished.
#    fig.cap = "..." adds a caption to graphical results.
#    results='asis' = output as-is, i.e., write raw results from R into the output document
```


```{r include=FALSE}
# Borrar toda las variables
### rm(list=ls())
```

***
```{r}
# List of libraries
library(foreign)
library(dplyr)
library(pander)
library(car)
library(ca)

library(gridExtra)
library(grid)
library(lattice)
library(ggplot2)
library(ggrepel)

library(factoextra)

library("RcmdrMisc")
library(cluster)
library(RANN)

library(diverse)
library(corrplot)

```

```{r}
# TODO: Mostrar u ocultar resultados de chunks de una variable
doc4JRB <- FALSE
```


https://bookdown.org/yihui/rmarkdown-cookbook/results-asis.html#results-asis

https://bookdown.org/yihui/rmarkdown-cookbook/reuse-chunks.html

https://bookdown.org/yihui/rmarkdown-cookbook/knit-expand.html

https://bookdown.org/yihui/rmarkdown-cookbook/child-document.html#child-document


```{r}
library(log4r)
# Create a new logger object with create.logger().
logger_analysis <- create.logger()
# Set the logger's file output.
logfile(logger_analysis) <- 'cis_2020_all_analisis.log'
# Set the current level of the logger.
level(logger_analysis) <- "DEBUG"
# level(logger_analysis) <- "INFO"
# At priority level INFO, a call to debug() won't print anything.
# debug(logger_analysis, 'A Debugging Message')
info(logger_analysis,  'Starting script')
# warn(logger_analysis, 'A Warning Message')
# error(logger_analysis, 'An Error Message')
# fatal(logger_analysis, 'A Fatal Error Message')
```


```{r eval=FALSE}
# GitHub connection
# http://destio.us.es/calvo/asignaturas/ge_esco/tutorialusargitgithubrstudio/UsarGitGithubconRStudio.html
#
library(gitcreds)
gitcreds::gitcreds_set()
```


\pagebreak

# Análisis de correspondencias múltiples
Datos cualitativos procedentes de encuestas realizadas por el  [Centro de Investigaciones Sociológicas (CIS)](https://www.cis.es) en septiembre de 2020:
[Encuesta 3293/0 POSTELECTORAL DEL PAÍS VASCO. ELECCIONES AUTONÓMICAS 2020](https://www.cis.es/cis/opencm/ES/1_encuestas/estudios/listaMuestras.jsp?estudio=14522).

# Descripción del fichero de datos.

Para conocer las preguntas consultar el fichero: "Estudio: Postelectoral Autonómicas País Vasco 2020 Clave: ECIS3293" del link mencionado anteriormente.


```{r}
# We have to filter CIS 2020 data previously. It spends a lot of time for it's calculations, thus we have made those calculations in an other script and now we load those results.
require(log4r)

cis_2020_cuisine_file <- file.path(getwd(), "cis_2020_cuisine_file.RData")
if (file.exists(cis_2020_cuisine_file)) {
  load(cis_2020_cuisine_file)
  log4r::info(logger_analysis, paste("cis_2020_cuisine_file (", cis_2020_cuisine_file, ") exists =", file.exists(cis_2020_cuisine_file)))
}else{
  log4r::error(logger_analysis, paste("File", cis_2020_cuisine_file, "DOES NOT EXIST. You must create this file using the script Cuisine.Rmd"))
  stop(paste("File", cis_2020_cuisine_file, "DOES NOT EXIST. You must create this file using the script Cuisine.Rmd"))}
```

```{r}
# P20 pollitical parties indices
# levels(cis_2020_df$P20)
P20_idx_11_pnv <- 5
P20_idx_12_bildu <- 6
P20_idx_2_psoe <- 2
P20_idx_21_podem <- 10
P20_idx_1_pp <- 1
P20_idx_18_vox <- 8
P20_idx_95_otro <- 14
P20_idx_96_blan <- 15
P20_idx_77_nul <- 13
P20_idx_97_abs <- 16
P20_idx_98_nr <- 17
P20_idx_99_nc <- 18

P20_idx_ciu <- 3
P20_idx_iu <- 4
P20_idx_pacm <- 7
P20_idx_ver <- 9
P20_idx_equ <- 11
P20_idx_escBl <- 12

# Test
# levels(cis_2020_df$P20)[c(P20_idx_1_pp, P20_idx_2_psoe, P20_idx_ciu, P20_idx_iu, P20_idx_11_pnv, P20_idx_12_bildu, P20_idx_pacm, P20_idx_18_vox, P20_idx_ver, P20_idx_21_podem, P20_idx_equ, P20_idx_escBl, P20_idx_77_nul, P20_idx_95_otro, P20_idx_96_blan,  P20_idx_97_abs, P20_idx_98_nr, P20_idx_99_nc)]
```


Ahora, realizamos el ACM en todas las columnas seleccionadas:
```{r ACM}
require(ca) 
cis_2020_ca_00 <- mjca(cis_2020_df[, included_cols_idx])
```

Por defecto la función `mjca` toma el método de escalado `lambda = "adjusted"`, con lo que únicamente se consideran los valores propios obtenidos en el ACM mayores que $\frac{1}{Q} =$
```{r echo=FALSE, results='asis'}
eigen_inertia_e <- 1/Q
### cat("\\frac{1}{", Q, "} = ",round(1/Q, digits = 4), ".", sep = "")
cat(round(eigen_inertia_e, digits = 4), ".", sep = "")
```

```{r}
cis_2020_ca_00_summ <- summary(cis_2020_ca_00)
numDim <- length(which(cis_2020_ca_00_summ$scree[,2] > (eigen_inertia_e/2)))

# if (numDim < 6) numDim <- 6
```
Por lo tanto en nuestro caso el número de dimensiones será:
```{r echo=FALSE, results='asis'}
cat(numDim)
```


## Datos objetivos y datos de opinión
Debemos tener en cuenta que hay una serie de variables que son datos objetivos de la persona como por ejemplo su provincia de empadronamiento. A estas características las llamaremos variables *ilustrativas*, que son:

```{r echo=FALSE, results='asis'}
# cat(paste0("'", included_cols, "'", collapse = ", "), sep = "")
# 'PROV', 'MUN', 'CAPITAL', 'TIPO_TEL', 'SEXO', 'A0a', 'P3_1', 'P3_2', 'P3_3', 'P3_4', 'P5', 'P6', 'P8_1', 'P8_2', 'P8_3', 'P8_4', 'P10_2', 'P10_3', 'P10IMPRESA', 'P10DIGITAL', 'P10TV', 'P10RADIO', 'P11_1', 'P11_2', 'P11_3', 'P11_4', 'P11_5', 'P11_7', 'P11_9', 'P12_1', 'P12_2', 'P12_3', 'P12_4', 'P12_5', 'P12_6', 'P12_7', 'P12_9', 'P13_1', 'P13_2', 'P13_3', 'P13_4', 'P13_5', 'P14', 'P14A_11', 'P14A_12', 'P14A_2', 'P14A_21', 'P14A_1', 'P14A_18', 'P14A_95', 'P14A_98', 'P14A_99', 'P15', 'P15A_11', 'P15A_12', 'P15A_2', 'P15A_21', 'P15A_1', 'P15A_18', 'P15A_95', 'P15A_98', 'P15A_99', 'P16', 'P16A_11', 'P16A_12', 'P16A_2', 'P16A_21', 'P16A_1', 'P16A_18', 'P16A_95', 'P16A_98', 'P16A_99', 'P17_1', 'P17_2', 'P17_3', 'P18', 'P19', 'P19A01', 'P19A02', 'P20', 'P20A_2', 'P21', 'P21A', 'P21B_2', 'P22', 'P23', 'P24_1', 'P24_2', 'P24_3', 'P24_4', 'PARTICIPACIONA', 'RECUVOTOA', 'P26_1', 'P26_2', 'P27', 'P29', 'PARTICIPACIONG', 'RECUVOTOG', 'RELIGION', 'FRECUENCIARELI', 'ESTADOCIVIL', 'SITLAB', 'CNO11', 'RELALAB', 'IA_APLAZADA', 'IA_MODIFICADA', 'IA_SUPERVISADA', 'RVAUTO16', 'RECUERDO', 'ESTUDIOS', 'CLASESUB', 'TAMUNI_GRUPO', 'EDAD_GRUPO', 'P1_GRUPO', 'P1A_GRUPO', 'P1B_GRUPO', 'P2_GRUPO', 'P4_GRUPO', 'P5A_GRUPO', 'P7_GRUPO', 'P9_GRUPO', 'P9A_GRUPO', 'P9B_GRUPO', 'P10_1_GRUPO', 'P10A_GRUPO', 'P10B_GRUPO', 'P10C_GRUPO', 'P10D_GRUPO', 'P18A_GRUPO', 'P18B_GRUPO', 'P20A_1_GRUPO', 'P21B_1_GRUPO', 'P21C_GRUPO', 'P24_5_GRUPO', 'P24_6_GRUPO', 'P24_7_GRUPO', 'P26_3_GRUPO', 'P26_4_GRUPO', 'P26_5_GRUPO', 'P26_6_GRUPO', 'P28_GRUPO', 'ESCIDEOL_GRUPO', 'ESCIDEOLPAR_1_GRUPO', 'ESCIDEOLPAR_2_GRUPO', 'ESCIDEOLPAR_3_GRUPO', 'ESCIDEOLPAR_4_GRUPO', 'ESCIDEOLPAR_5_GRUPO', 'ESCIDEOLPAR_6_GRUPO', 'ESCIDEOLPAR_7_GRUPO', 'ESCUELA_GRUPO', 'NIVELESTENTREV_GRUPO', 'CLASESOCIAL_GRUPO', 'IA_E1_DIA_GRUPO', 'IA_E2_GRUPO', 'IA_E4_GRUPO', 'IA_C2_GRUPO', 'P19ACOM_GRUPO', 'RVAUTO20_RECODE'

# Select some illustrative variables
illustrative_vars_v01 <- c('PROV', 'MUN', 'CAPITAL', 'TIPO_TEL', 'SEXO', 'A0a', 
                       'PARTICIPACIONA', 'RECUVOTOA', 
                       'PARTICIPACIONG', 'RECUVOTOG', 
                       'ESTADOCIVIL', 'SITLAB', 'CNO11', 'RELALAB', 
                       'IA_APLAZADA', 'IA_MODIFICADA', 'IA_SUPERVISADA', 'P20',
                       'RVAUTO20_RECODE', 'RVAUTO16', 'RECUERDO', 'ESTUDIOS', 
                       'TAMUNI_GRUPO', 'EDAD_GRUPO', 'P1_GRUPO', 'P1A_GRUPO', 'P1B_GRUPO', 'P2_GRUPO', 
                       'NIVELESTENTREV_GRUPO', 
                       'IA_E1_DIA_GRUPO', 'IA_E2_GRUPO', 'IA_E4_GRUPO', 'IA_C2_GRUPO')

# illustrative_vars <- c('RECUVOTOA', 'RECUVOTOG', 'RVAUTO20_RECODE', 'RVAUTO16', 'RECUERDO')

# JRB: Incluir edad, tamano municipio, sexo, situacion laboral, estudios
illustrative_vars_v02 <- c('PROV', 'MUN', 'CAPITAL', 'TIPO_TEL', 
                       'RECUVOTOA', 'RECUVOTOG', 
                       'ESTADOCIVIL', 
                       'P1_GRUPO', 'P1A_GRUPO', 'P1B_GRUPO', 'P2_GRUPO', 
                       'IA_APLAZADA', 'IA_MODIFICADA', 'IA_SUPERVISADA', 'P20',
                       'RVAUTO20_RECODE', 'RVAUTO16', 'RECUERDO', 
                       'IA_E1_DIA_GRUPO', 'IA_E2_GRUPO', 'IA_E4_GRUPO', 'IA_C2_GRUPO')

# JRB: Incluir edad, tamano municipio, sexo, situacion laboral, estudios, nacionalidad, lugar de nacimiento, comunidad autonoma de nacimiento, lengua materna
illustrative_vars_v03 <- c('PROV', 'MUN', 'CAPITAL', 'TIPO_TEL', 
                       'RECUVOTOA', 'RECUVOTOG', 
                       'ESTADOCIVIL',  
                       'IA_APLAZADA', 'IA_MODIFICADA', 'IA_SUPERVISADA', 'P20',
                       'RVAUTO20_RECODE', 'RVAUTO16', 'RECUERDO', 
                       'IA_E1_DIA_GRUPO', 'IA_E2_GRUPO', 'IA_E4_GRUPO', 'IA_C2_GRUPO')

illustrative_vars <- illustrative_vars_v03
# Calculate spare variables
opinion_vars <- included_cols[which(!(included_cols %in% illustrative_vars))]

cat(paste0("`",illustrative_vars, "`", collapse = ", "), sep = "")

# length(illustrative_vars) + length(opinion_vars)
```

El resto de preguntas pueden considerarse de opinión. El ACM trata de ubicar los datos objetivos entre las diferentes escalas de opiniones.

# Selección de dimensiones más representativas

Se realiza una primera tentativa de ACM sólo con las variables de opinión:
```{r}
# Queremos representar algunas variables ilustrativas como columnas suplementarias.
# Por tanto hay que reordenar el dataframe poniendo las ilustrativas al final.
# Ademas debemos elegir lambda = "Burt"
cis_2020_acm_df <- cis_2020_df[,c(opinion_vars, illustrative_vars)]
# Seleccion de columnas suplementarias para mostar en el plano factorial
suplementary_cols <- c('RECUVOTOA', 
                       'RECUVOTOG', 
                       'RVAUTO20_RECODE', 'P20', 'RVAUTO16', 'RECUERDO')

suplementary_cols_idx <- which(colnames(cis_2020_acm_df) %in% suplementary_cols)
opinion_vars_idx <- which(colnames(cis_2020_acm_df) %in% opinion_vars)
```


```{r ACM01}
require(ca)
### cis_2020_ca_opi01 <- mjca(cis_2020_acm_df[,opinion_vars], nd = numDim)
cis_2020_ca_opi01 <- mjca(cis_2020_acm_df, nd = numDim, lambda = "Burt", supcol = suplementary_cols_idx, subsetcol = opinion_vars_idx)

cis_2020_ca_opi01_summ <- summary(cis_2020_ca_opi01)
# print(cis_2020_ca_opi01_summ)

plot.mjca(cis_2020_ca_opi01, labels = c(2,0))
# plot.mjca(cis_2020_ca_opi01)
```

Inercias de los autovalores principales:
```{r}
require(pander)
aux_tbl <- as.data.frame(cis_2020_ca_opi01_summ$scree[1:numDim,])
colnames(aux_tbl) <- c("Dim", "Valor", "%", "% acumul")
# panderOptions()
pander(aux_tbl, digits = c(1,5,3,3), keep.trailing.zeros = TRUE, caption = "Porcentaje de varianza explicada por cada autovalor.")
```

```{r}
# Save factors information
# We will get a data.frame with: "name", "mass", " qlt", " inr" and information of every factor: "k", "cor" and "ctr"
require(dplyr)
cis_2020_ca_opi01_factor <- dplyr::bind_rows(cis_2020_ca_opi01_summ$columns)
colnames(cis_2020_ca_opi01_factor) <- c(c("name", "mass", "qlt", "inr"), paste0(c("k", "cor", "ctr"), rep(1:numDim, each=3)))
```

Con 
```{r echo=FALSE, results='asis'}
cat(numDim)
```
 dimensiones se explica el 
```{r echo=FALSE, results='asis'}
# cat(round(100 * sum(cis_2020_ca_opi01$inertia.e[1:numDim]), digits = 1))
cat(cis_2020_ca_opi01_summ$scree[numDim,][4])
```
 % de la varianza.


Seleccionamos las modalidades más importantes de cada factor.
```{r}
percet_eigenvalue <- 0.85
```
```{r}
# Returns a data.frame sorted by contribution. It includes the minimum number of categories that covers percet_eigenvalue
factor_categories <- function(columns_factors, num_factor, percet_eigenvalue){
  k_idx <-   4+3*(num_factor-1)+1
  cor_idx <- 4+3*(num_factor-1)+2
  ctr_idx <- 4+3*(num_factor-1)+3
  
  # Sort by its contribution
  fctr_contribution_sort <- base::sort(columns_factors[,ctr_idx], decreasing = TRUE, index.return = TRUE)
  # Calculate percet_eigenvalue of whole eigenvalue
  i <- round(percet_eigenvalue*sum(columns_factors[,ctr_idx], na.rm = TRUE))
  # Calculate number of variables
  num_categories <- which.max(cumsum(fctr_contribution_sort$x) >= i)
  #  cbind() returns a matrix, and a matrix can only hold one data type we must use data.frame()
  table <- data.frame(1:num_categories,
                      columns_factors$name[fctr_contribution_sort$ix[1:num_categories]],
                      columns_factors$qlt[fctr_contribution_sort$ix[1:num_categories]],
                      columns_factors[,k_idx][fctr_contribution_sort$ix[1:num_categories]],
                      columns_factors[,cor_idx][fctr_contribution_sort$ix[1:num_categories]],
                      fctr_contribution_sort$x[1:num_categories],
                      round(100*fctr_contribution_sort$x[1:num_categories] / sum(fctr_contribution_sort$x), digits = 1))
  
  colnames(table) <- c("n", "Variable:modalidad", "qlt", "k", "cor", "ctr", "%")

  return(table)
}
```

Ya se dijo que se iban a representar 
```{r echo=FALSE, results='asis'}
cat(numDim)
```
 dimensiones.
 
Se analiza el contenido de cada dimensión de una en una teniendo en cuenta el significado de cada parámetro obtenido:

 + `qlt`: representa la *calidad* de esa modalidad. Es el $cos^2$ y mide el grado de asociación de una modalidad con esa dimensión.
 + `k`: nos da las coordenadas de la modalidad en esa dimensión (en ese eje).
 + `cor`: correlaciones al cuadrado entre la modalidad y la dimensión.
 + `ctr`: para interpretar cada dimensión se analizan las contribuciones  absolutas (`ctr`). Esta columna es la que realmente representa cuánto de importante es una modalidad dentro de esa dimensión. 

Disponemos de 
```{r echo=FALSE, results='asis'}
cat(length(opinion_vars))
```
 variables que abarcan 
```{r echo=FALSE, results='asis'}
i <- 0
for (j in opinion_vars) {
  i <- i + nlevels(cis_2020_acm_df[,j])
}
cat(i)
```
 modalidades. Precisamente cada una de estas modalidades va a contribuir (`ctr`) a crear cada dimensión.


## Dimensión 1
```{r}
num_categories_to_show <- 35
```

```{r}
i <- 1
# We want to show positive and negative categories of this dimension. And it is possible that only one side explains the wanted percentage, so we have to take extra categories from the other side to show.
# table with big percentage of eigenvalue
aux_tbl <- factor_categories(cis_2020_ca_opi01_factor, i, percet_eigenvalue)


# Select number of positive categories of table
n_categories_k_positive <- ifelse(length(which(aux_tbl$k > 0)) < num_categories_to_show, length(which(aux_tbl$k > 0)), num_categories_to_show)
# Select number of negative categories of table
n_categories_k_negative <- ifelse(length(which(aux_tbl$k < 0)) < num_categories_to_show, length(which(aux_tbl$k < 0)), num_categories_to_show)
```

En el **lado positivo del eje** las modalidades mejor representadas son:

```{r}
# Show positive categories
aux_idx <- which(aux_tbl$k > 0)[1:n_categories_k_positive]

require(pander)
pander(aux_tbl[aux_idx,], caption = paste0("Dimensión ", i, ". Contiene las ", n_categories_k_positive, " modalidades más significativas del eje positivo que abarcan el ", round(100 * sum(aux_tbl$ctr[aux_idx])/sum(cis_2020_ca_opi01_factor[,paste0("ctr",i)], na.rm = TRUE)), " % de la dimensión."))
```
```{r eval=FALSE, include=FALSE, echo=FALSE}
str_aux_1 <- sort(head(aux_tbl$`Variable:modalidad`[which(aux_tbl$k > 0)], n = n_categories_k_positive))
cat(paste0("`", str_aux_1, "`", collapse = ", "), ".", sep = "")
```

Para explicar el significado de un eje, hay que ver la contribución (`ctr`) de cada modalidad dentro de esa parte del eje. A continuación se explican las modalidades más significativa de este lado del eje en orden de preguntas (no por su contribución):

 + `(*)RECUVOTOA:Ciudadanos`
 + `P10DIGITAL:Menciona` = Fuentes utilizadas para informarse sobre las elecciones autonómicas del País Vasco de 2020: 
```{r echo=FALSE, results='asis'}
cat(attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) == 'P10DIGITAL'])
```
: 
```{r echo=FALSE, results='asis'}
cat(levels(cis_2020_df$P10DIGITAL)[1])
```
 + `P11_2:Menciona`, `P11_3:Menciona`
 + `P12_1:Menciona`, `P12_5:Menciona`, `P12_7:No menciona`
 + `P15:Sí`
 + `P15A_1:No menciona`, `P15A_2:No menciona`, `P15A_11:No menciona`, `P15A_12:Menciona`, `P15A_12:No menciona`, `P15A_18:No menciona`, `P15A_21:No menciona`, `P15A_95:No menciona`, `P15A_98:No menciona`, `P15A_99:No menciona`
 + `P16:Sí` =
```{r echo=FALSE, results='asis'}
cat(attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) == 'P16'])
```
: 
```{r echo=FALSE, results='asis'}
cat(levels(cis_2020_df$P16)[1])
```
   + `P16A_1:No menciona`, `P16A_2:No menciona`, ``P16A_11:No menciona`, `P16A_12:No menciona`, `P16A_18:No menciona`, `P16A_21:No menciona`, `P16A_95:No menciona`, `P16A_98:No menciona`, `P16A_99:No menciona` = No menciona a: 
```{r}
cat(paste(attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) %in% c('P16A_1', 'P16A_2', 'P16A_11', 'P16A_12', 'P16A_18', 'P16A_21', 'P16A_95', 'P16A_98', 'P16A_99')], collapse = ", "))
```
   + `P16A_11:Menciona`, `P16A_12:Menciona` = Sí menciona a: 
```{r}
cat(paste(attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) %in% c('P16A_11', 'P16A_12')], collapse = ", "))
```
  + `P27:Un Estado en el que se reconociese a las comunidades autónomas la posibilidad de convertirse en Estados independientes `
 + `P3_2:Sí`
 + `P3_3:Sí`
 + `P3_4:Sí`
 + `RELIGION:Ateo/a`
 
En resumen: Este eje lado del eje representa a las personas que ....

En el **lado negativo del eje** están las "variables:modalidades":

```{r}
# Show negative categories
aux_idx <- which(aux_tbl$k < 0)[1:n_categories_k_negative]
require(pander)

pander(aux_tbl[aux_idx,], caption = paste0("Dimensión ", i, ". Contiene las ", n_categories_k_negative, " modalidades más significativas del eje negativo que abarcan el ", round(100 * sum(aux_tbl$ctr[aux_idx])/sum(cis_2020_ca_opi01_factor[,paste0("ctr",i)], na.rm = TRUE)), " % de la dimensión."))
```

```{r eval=FALSE, include=FALSE, echo=FALSE}
str_aux_1 <- sort(head(aux_tbl$`Variable:modalidad`[which(aux_tbl$k < 0)], n = n_categories_k_negative))
cat(paste0("`", str_aux_1, "`", collapse = ", "), ".", sep = "")
```

Para explicar el significado de un eje, hay que ver la contribución (`ctr`) de cada modalidad dentro de esa parte del eje. A continuación se explican las modalidades más significativa de este lado del eje en orden de preguntas (no por su contribución):

+ `ESCIDEOL_GRUPO:N.C.`, `ESCIDEOLPAR_1_GRUPO:N.C.`, `ESCIDEOLPAR_1_GRUPO:N.S.`, `ESCIDEOLPAR_2_GRUPO:N.C.`, `ESCIDEOLPAR_2_GRUPO:N.S.`, `ESCIDEOLPAR_3_GRUPO:N.C.`, `ESCIDEOLPAR_3_GRUPO:N.S.`, `ESCIDEOLPAR_4_GRUPO:N.C.`, `ESCIDEOLPAR_4_GRUPO:N.S.`, `ESCIDEOLPAR_5_GRUPO:N.C.`, `ESCIDEOLPAR_5_GRUPO:N.S.`, `ESCIDEOLPAR_6_GRUPO:N.C.`, `ESCIDEOLPAR_6_GRUPO:N.S.`, `ESCIDEOLPAR_7_GRUPO:N.C.`, `ESCIDEOLPAR_7_GRUPO:N.S.`, `P10_2:N.C.`, `P12_7:Menciona`, `P24_1:N.C.`, `P24_2:N.C.`, `P24_3:N.C.`, `P24_4:N.C.`, `P24_5_GRUPO:N.C.`, `P24_6_GRUPO:N.C.`, `P24_7_GRUPO:N.C.`, `P26_1:N.C.`, `P26_2:N.C.`, `P26_3_GRUPO:N.C.`, `P26_4_GRUPO:N.C.`, `P26_5_GRUPO:N.C.`, `P26_6_GRUPO:N.C.`, `P29:N.C.`, `P3_1:No`, `P3_3:No`, `P5A_GRUPO:N.C.`, `P6:Nada`


Este lado del eje representa a las personas que ...


**JRB**

En resumen: Este eje representa a las personas que por un extremo ...


```{r}
numDims_to_show <- numDim # numDim
```


```{r section_dimension, echo=FALSE, results='asis'}
# Generar automaticamente por programa el resto de capitulos

for (i in 2:numDims_to_show) {
  # Title ---------------------------------------
  cat("\n\n## Dimension", i, "\n")
  
  # A comment ----------------------------------
  cat("\nSe muestran las tablas con las variables más representativas de esta dimensión.")
  cat("\nEn el **lado positivo del eje** las modalidades mejor representadas son:\n\n")
  
  # Prepare tables ------------------------------
  # We want to show positive and negative categories of this dimension. And it is possible that only one side explains the wanted percentage, so we have to take extra categories from the other side to show.
  # table with big percentage of eigenvalue
  aux_tbl <- factor_categories(cis_2020_ca_opi01_factor, i, percet_eigenvalue)
  
  # Select number of positive categories of table
  n_categories_k_positive <- ifelse(length(which(aux_tbl$k > 0)) < num_categories_to_show, length(which(aux_tbl$k > 0)), num_categories_to_show)
  # Select number of negative categories of table
  n_categories_k_negative <- ifelse(length(which(aux_tbl$k < 0)) < num_categories_to_show, length(which(aux_tbl$k < 0)), num_categories_to_show)
  
  # Show positive categories --------------------
  aux_idx <- which(aux_tbl$k > 0)[1:n_categories_k_positive]
  
  require(dplyr)
  require(pander)
  # pander tries to return a knit_asis class object when run inside knitr, but for loops/vectorized functions this results in incorrect output. The recommended way to solve this is to disable this behavior by setting knitr.auto.asis to FALSE using panderOptions. However, we also need to tell knitr to convert the table on the fly by specifying results='asis' in the chunk options
  panderOptions('knitr.auto.asis', FALSE)
  pander(aux_tbl[aux_idx,], caption = paste0("Dimensión ", i, ". Contiene las ", n_categories_k_positive, " modalidades más significativas del eje positivo que abarcan el ", round(100 * sum(aux_tbl$ctr[aux_idx])/sum(cis_2020_ca_opi01_factor[,paste0("ctr",i)], na.rm = TRUE)), " % de la dimensión."))
  
  ## Sorted categories
  ## str_aux_1 <- sort(head(aux_tbl$`Variable:modalidad`[which(aux_tbl$k > 0)], n = n_categories_k_positive))
  ## cat(paste0("`", str_aux_1, "`", collapse = ", "), sep = "")
    
  
  cat("\nEn el **lado negativo del eje** están las \"variables:modalidades\":\n")
  
  # Show negative categories --------------------
  aux_idx <- which(aux_tbl$k < 0)[1:n_categories_k_negative]
  require(pander)
  pander(aux_tbl[aux_idx,], caption = paste0("Dimensión ", i, ". Contiene las ", n_categories_k_negative, " modalidades más significativas del eje negativo que abarcan el ", round(100 * sum(aux_tbl$ctr[aux_idx])/sum(cis_2020_ca_opi01_factor[,paste0("ctr",i)], na.rm = TRUE)), " % de la dimensión."))
  
  ## Sorted categories
  ## str_aux_1 <- sort(head(aux_tbl$`Variable:modalidad`[which(aux_tbl$k < 0)], n = n_categories_k_negative))
  ## cat(paste0("`", str_aux_1, "`", collapse = ", "), sep = "")
}
```


# Individuos

```{r}
# Color for every pollitical party
require(ggplot2)
RVAUTO20_RECODE_breaks <- c('PP+C\'s', 'PSE-EE-PSOE', 
                                  'EAJ-PNV', 'EH Bildu', 
                                  'PACMA', 'VOX', 
                                  'Elkarrekin Podemos', 
                                  'Voto nulo', 
                                  'EQUO Berdeak',
                                  'En blanco', 'No votó/abstención', 'No recuerda', 'N.C.')
RVAUTO20_RECODE_values <- c("cyan", "red3", 
                                 "darkseagreen1", "orangered", 
                                 "navajowhite4", "cyan3",
                                 "darkorchid1", 
                                 "yellow", 
                                 "darkgreen", 
                                 "yellow", "yellow", "yellow", "gray40")


# RVAUTO20_RECODE color codes
scale_color_manual_RVAUTO20_RECODE <- scale_color_manual(breaks = RVAUTO20_RECODE_breaks, values = RVAUTO20_RECODE_values)
scale_fill_manual_RVAUTO20_RECODE <- scale_fill_manual(breaks = RVAUTO20_RECODE_breaks, values = RVAUTO20_RECODE_values)
```

```{r}
# Colors for neighbours
neighbours_lbl <- 'Cercanos EB'
aux_idx <- which(RVAUTO20_RECODE_breaks == "EQUO Berdeak")
scale_color_manual_P20_NEIGH <- scale_color_manual(name = neighbours_lbl,
                                                   breaks = c(RVAUTO20_RECODE_breaks[1:aux_idx], 
                                                              neighbours_lbl, 
                                                              RVAUTO20_RECODE_breaks[-(1:aux_idx)]),
                                                   values = c(RVAUTO20_RECODE_values[1:aux_idx], 
                                                              "green2", 
                                                              RVAUTO20_RECODE_values[-(1:aux_idx)]))
```


```{r}
gg_plot_MCA_rows <- function(dimX = 1, dimY = 2, coord_type = "standard"){
  require(ca)
  # Extracting principal from mjca objects
  # type = c("standard", "principal", "symmetric", "rowprincipal", "colprincipal", "symbiplot", "rowgab", "colgab", "rowgreen", "colgreen")
  aux_coord <- ca::cacoord(cis_2020_ca_opi01, type = coord_type, dim = c(dimX, dimY), cols = FALSE, rows = TRUE)
  # dataframe with dimensions coordinates
  my_title <- "Individuos en el plano factorial"
  row_coord_df <- cbind.data.frame(aux_coord[,1],
                                 aux_coord[,2],
                                 # 1:nrow(aux_coord),
                                 rownames(cis_2020_acm_df),
                                 cis_2020_acm_df$RVAUTO20_RECODE)
  
  colnames(row_coord_df) <- c("dimX", "dimY", "name", "Votos 2020")

  require(ggplot2)
  require(ggrepel)
  # Se crea el objeto con el grafico
  ggplot(row_coord_df, aes(x=row_coord_df$dimX, y=row_coord_df$dimY, color=row_coord_df$`Votos 2020`)) +
    geom_point() + geom_rug() +
    # xlim(-2.6, 3.5) + ylim(-2.1,3.8)+
    geom_text_repel(aes(label=row_coord_df$name),hjust=0, vjust=0,size=3.3) +
    # scale_colour_brewer(palette = "Set1") +
    geom_vline(xintercept = 0) + geom_hline(yintercept = 0) + 
    ggtitle(my_title) +
    xlab(paste("Dimension ", dimX, " (", round(100 * cis_2020_ca_opi01$inertia.e[dimX], digits = 1) , "% )", sep = "")) +
    ylab(paste("Dimension ", dimY, " (", round(100 * cis_2020_ca_opi01$inertia.e[dimY], digits = 1) , "% )", sep = "")) +
    labs(color = "Votos 2020") +
    scale_color_manual_RVAUTO20_RECODE
}
# Replace ' character with escape character \\'
# sprintf("c(%s)", paste0("'", gsub(pattern = "'", replacement = "\\\\'", x = levels(cis_2020_acm_df$RVAUTO20_RECODE)), "'", collapse = ", "))
```

A continuación se muestran a los individuos en diferentes planos factoriales.

```{r plot_MCA_rows}
for (i in seq(numDims_to_show-1)) {
  print(gg_plot_MCA_rows(dimX = i, dimY = i+1))
}
```

## Individuos de *EQUO Berdeak*

```{r}
# Find rows coordinates in factorial space
# type = c("standard", "principal", "symmetric", "rowprincipal", "colprincipal", "symbiplot", "rowgab", "colgab", "rowgreen", "colgreen")
aux_tbl <- ca::cacoord(cis_2020_ca_opi01, type = "standard", dim = c(1:numDim), cols = FALSE, rows = TRUE)
# Append rows coordinates to data.frame
cis_2020_acm_df <- cbind.data.frame(cis_2020_acm_df, aux_tbl)
```

Se toma a todos los que han votado a *EQUO Berdeak* en 2020. Es de esperar que haya opiniones variadas dentro de este conjunto, Por ello se buscan grupos homogeneos con opiniones coincidentes. A cada uno de esostos subgrupos *coincidentes* les llamaremos *clusters*.


```{r}
# Plot selected points a its neighbours
gg_plot_EB <- function(dimX = 1, dimY = 2){

  my_title <- "Individuos de Equo-Berdeak en 2020"
  row_coord_df <- cbind.data.frame(cis_2020_acm_df[EB_rows, paste0("Dim",dimX)],
                                 cis_2020_acm_df[EB_rows, paste0("Dim",dimY)],
                                 rownames(cis_2020_acm_df)[EB_rows],
                                 cis_2020_acm_df$RVAUTO20_RECODE[EB_rows])
  
  colnames(row_coord_df) <- c("dimX", "dimY", "name", "EQUO_BERDEAK")

  require(ggplot2)
  require(ggrepel)
  # Se crea el objeto con el grafico
  gg_obj <- ggplot(row_coord_df, aes(x=dimX, y=dimY, color=EQUO_BERDEAK)) +
    geom_point() + geom_rug() +
    # xlim(-2.6, 3.5) + ylim(-2.1,3.8)+
    geom_text_repel(aes(label=name),hjust=0, vjust=0,size=3.3, max.overlaps = 20) +
    # scale_colour_brewer(palette = "Set1") +
    geom_vline(xintercept = 0) + geom_hline(yintercept = 0) + 
    ggtitle(my_title) +
    xlab(paste("Dimension ", dimX, " (", round(100 * cis_2020_ca_opi01$inertia.e[dimX], digits = 1) , "% )", sep = "")) +
    ylab(paste("Dimension ", dimY, " (", round(100 * cis_2020_ca_opi01$inertia.e[dimY], digits = 1) , "% )", sep = "")) +
    # levels(cis_2020_acm_df$RVAUTO20_RECODE)
    scale_color_manual_RVAUTO20_RECODE
  
  return(gg_obj)
}
```

Se muestran a todos los vecinos de *EQUO Berdeak* en diferentes planos factoriales.

```{r plot_equo}
for (i in seq(numDims_to_show-1)) {
  print(gg_plot_EB(dimX = i, dimY = i+1))
}
```

## Outliers *EQUO Berdeak*

Se buscan individuos que se alejan *demasiado* de la media que se podrían interpretar como personas que realmente votan a *EQUO Berdeak* pero que están alejados de sus posturas, o bien como encuestas erroneas, o en el peor de los casos individuos que no han dicho la verdad al ser encuestados.


```{r}
# Save EB individuals
EB_df <- cis_2020_acm_df[EB_rows,]
aux_tbl <- subset(x = EB_df, select = c(paste0("Dim", 1:numDim)))
# We look for a centered population
EB_centered_df <- as.data.frame(scale(x=aux_tbl, center = TRUE, scale = FALSE))
# Calculate distance from the center = norm of a vector
EB_centered_df$Distancia <- 0
for (i in 1:nrow(EB_centered_df)) {
  EB_centered_df$Distancia[i] <- norm(x = EB_centered_df[i,], type = "2")
}


require(ggplot2)
gg_EB_boxplot <- ggplot(data=EB_centered_df, aes(x=Distancia)) + 
  geom_boxplot() +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

gg_EB_histogram <- ggplot(EB_centered_df, aes(x=Distancia)) + 
  geom_histogram(color="black", fill="white", bins=10) +
  scale_y_continuous(breaks = seq(0, 12, by=2))

library(gridExtra)
require(gridExtra)
grid.arrange(gg_EB_boxplot, gg_EB_histogram, ncol=2)
```


Distancias de los outliers que están más allá del 95% de la media del grupo:

```{r}
outliers_idx <-which(EB_centered_df$Distancia > (mean(EB_centered_df$Distancia) + 2*sd(EB_centered_df$Distancia)))
EB_centered_df$Distancia[outliers_idx]
```

Outliers. Número de encuesta:
```{r}
rownames(EB_centered_df[outliers_idx,])
```



```{r}
summary(EB_centered_df$Distancia)
```


## Clusters de los votantes de *EQUO Berdeak*

### Clusters y outliers

```{r}
# lista_mtdos <- c("ward.D", "ward.D2", "complete", "single", "average", "mcquitty", "median", "centroid")
mtdo_usado <- "ward.D2" # "ward.D"
formula_all_dims <- as.formula(paste("~-1 +", paste0("Dim",1:numDim, collapse = "+")))
# Distancia euclidea al cuadrado entre los elementos de la matriz
dist_indiv_EB <- stats::dist(model.matrix(formula_all_dims, EB_df))^2
HClust_EB <- hclust(dist_indiv_EB , method= mtdo_usado)
```

se puede buscar el número óptimo de clusters (`k`) usando la función `daisy` (Dissimilarity Matrix Calculation) que computa las desigualdades en las distancias entre parejas. En este caso para obtener el número óptimo de clusters y su composición se ha usado la métrica euclídea al cuadrado para computar las distancias.

```{r}
# Funcion para calcular el k optimo
# Creamos una funcion para calcular la matriz de distancia dos a dos con los grupos
# daisy: Compute all the pairwise dissimilarities (distances) between observations in the data set.
# https://www.rpubs.com/dvallslanaquera/clustering
grpdist <- function(X, metrica="gower"){
  # metrica = "euclidean", "gower"
  # Se carga la libreria "cluster"
  require(cluster)
  gr <- as.data.frame(as.factor(X))
  distgr <- daisy(gr, metrica)
  distgr
  }
```



```{r}
# Se genera el cluster optimo y se representa en el plano
require(gridExtra)
require(grid)
require(ggplot2)
require(lattice)

# La matriz dist_indiv_EB contiene las distancias euclideas al cuadrado.

require(cluster)

# data frame auxiliar
kt <- data.frame(k=1:nrow(EB_df), r=0)

# Se elige el numero de clusters optimo
for(i in 2:(nrow(EB_df)-1)){
  gr <- cutree(HClust_EB, i)
  distgr <- grpdist(gr, "gower")
  mt <- cor(dist_indiv_EB, distgr, method="pearson")
  kt[i,2] <- mt
}

num_clusters_EB <- which.max(kt$r)
### num_clusters_EB <- num_clusters_EB + 1 ### ATENCION CAMBIAR

# Se crea una columna con el numero de cluster asignado a ese individuo
require(RcmdrMisc)
EB_df$num_cluster <- assignCluster(model.matrix(formula_all_dims, EB_df),
                                                 EB_df, 
                                                 cutree(HClust_EB, k = num_clusters_EB))

## pick colour
# library(RColorBrewer)
# EB_cluster_palette <- brewer.pal(n=num_clusters_EB, "Set2")
EB_cluster_palette <- c("blue", "cyan", "darkgray", "green", "violet", "red", "bisque2", "goldenrod2")[1:num_clusters_EB]

recodes_str <- paste0((1:num_clusters_EB), "=", paste0("'", EB_cluster_palette, "'"), collapse = "; ")
require(pander)
require(dplyr)
pander(EB_df %>% dplyr::count(num_cluster), .drop=FALSE)
```

```{r}

EB_cluster_scale_color <- scale_color_manual(name = "Clusters",
                                             breaks = c(1:num_clusters_EB),
                                             values = EB_cluster_palette)

### EB_cluster_fill_color <- scale_fill_manual(breaks = c(1:num_clusters_EB),
###                       values = EB_cluster_palette)



# Funcion que muestra los individuos en un plano factorial con las dimensiones (dimX, dimY) y colorea los clusters
gg_space_cluster <- function(dimX = 1, dimY = 2, k.optimo=3, titulo = "") {
  
  # dimX = 1
  # dimY = 2
  # k.optimo <- 6
  # titulo = ""

  # create column name
  C1 <- paste0("Dim", dimX)
  C2 <- paste0("Dim", dimY)

  figura <- ggplot(data=EB_df, aes(x=.data[[C1]], y=.data[[C2]], color=num_cluster)) +
    geom_point() + geom_rug() +
    geom_vline(xintercept = 0) + geom_hline(yintercept = 0) +
    geom_text_repel(aes(label=rownames(EB_df)),hjust=0, vjust=0, size=3.3) +
    EB_cluster_scale_color +
    #geom_text(aes(label=rownames(EB_df)),hjust=0, vjust=0, size=3.3) +
    theme(legend.position="top") + ggtitle(titulo)
  
  return(figura)
}
```



```{r plot_clusters01}
# Se crea el texto que se mostrara con la figura
# Distribución de los vehículos en cada cluster:
distrib_clusters_EB <-  summary(as.factor(cutree(HClust_EB, k = num_clusters_EB)))
txt_distrib_clusters_EB <- paste0((1:length(distrib_clusters_EB)), ":", distrib_clusters_EB, collapse = ", ")
txt_distrib_clusters_EB_rev <- paste0((length(distrib_clusters_EB):1), ":", rev(distrib_clusters_EB), collapse = ", ")

txt_distrib_clusters_EB_colors <- paste0((1:length(distrib_clusters_EB)), ":", EB_cluster_palette, collapse = ", ")


# Dendograma
#
# TODO: poner una legend en el dendograma para mostrar numero de cluster y sus color
#
require(factoextra)
fviz_dendograma_ACM <- fviz_dend(HClust_EB, 
                               k = num_clusters_EB, 
                               # k_colors = EB_cluster_palette,
                               k_colors = rev(EB_cluster_palette), # reverse colors!!!!
                               rect = TRUE, 
                               show_labels = TRUE, 
                               # main = "Cluster Dendrograma para individuos cercanos a EQUO Berdeak", 
                               main = txt_distrib_clusters_EB_rev, 
                               sub = txt_distrib_clusters_EB)
```




```{r}
require(pander)
pander(distrib_clusters_EB, caption = "Distribución de los cluster")
```

```{r}
fviz_dendograma_ACM
```

```{r}
for (i in seq(numDims_to_show-1)) {
  print(gg_space_cluster(dimX = i, dimY = i+1, k.optimo = num_clusters_EB, titulo = "Clusters de individuos cercanos a EQUO Berdeak"))
}
```

El cluster número 
```{r echo=FALSE, results='asis'}
EB_outlier_cluster <- which.min(distrib_clusters_EB)
cat(EB_outlier_cluster)
```
 tiene 
```{r echo=FALSE, results='asis'}
cat(distrib_clusters_EB[EB_outlier_cluster])
```
 elemento que corresponde con la encuesta número:
```{r echo=FALSE, results='asis'}
outliers_2_idx <- which(EB_df$num_cluster == EB_outlier_cluster)
EB_outliers_rowname <- rownames(EB_df)[outliers_2_idx]
cat(rownames(EB_df)[outliers_2_idx])
```
 
. Parace que siempre está aislado del resto. Existe la posibilidad de que este individuo no haya dicho la verdad en su encuesta. Lo eliminamos y repetimos el análisis cluster.



### Clusters, segundo intento

```{r}
EB_df <- EB_df[-outliers_2_idx,]
```

```{r}
# erase outlier from list
EB_rows <- EB_rows[-outliers_2_idx]
```


```{r}
# lista_mtdos <- c("ward.D", "ward.D2", "complete", "single", "average", "mcquitty", "median", "centroid")
mtdo_usado <- "ward.D2" # "ward.D"
formula_all_dims <- as.formula(paste("~-1 +", paste0("Dim",1:numDim, collapse = "+")))
# Distancia euclidea al cuadrado entre los elementos de la matriz
dist_indiv_EB <- stats::dist(model.matrix(formula_all_dims, EB_df))^2
HClust_EB <- hclust(dist_indiv_EB , method= mtdo_usado)
```

se puede buscar el número óptimo de clusters (`k`) usando la función `daisy` (Dissimilarity Matrix Calculation) que computa las desigualdades en las distancias entre parejas. En este caso para obtener el número óptimo de clusters y su composición se ha usado la métrica euclídea al cuadrado para computar las distancias.

```{r}
# Funcion para calcular el k optimo
# Creamos una funcion para calcular la matriz de distancia dos a dos con los grupos
# daisy: Compute all the pairwise dissimilarities (distances) between observations in the data set.
# https://www.rpubs.com/dvallslanaquera/clustering
grpdist <- function(X, metrica="gower"){
  # metrica = "euclidean", "gower"
  # Se carga la libreria "cluster"
  require(cluster)
  gr <- as.data.frame(as.factor(X))
  distgr <- daisy(gr, metrica)
  distgr
  }
```



```{r}
# Se genera el cluster optimo y se representa en el plano
require(gridExtra)
require(grid)
require(ggplot2)
require(lattice)

# La matriz dist_indiv_EB contiene las distancias euclideas al cuadrado.

require(cluster)

# data frame auxiliar
kt <- data.frame(k=1:nrow(EB_df), r=0)

# Se elige el numero de clusters optimo
for(i in 2:(nrow(EB_df)-1)){
  gr <- cutree(HClust_EB, i)
  distgr <- grpdist(gr, "gower")
  mt <- cor(dist_indiv_EB, distgr, method="pearson")
  kt[i,2] <- mt
}

num_clusters_EB <- which.max(kt$r)
### num_clusters_EB <- num_clusters_EB + 1 ### ATENCION CAMBIAR

# Se crea una columna con el numero de cluster asignado a ese individuo
require(RcmdrMisc)
EB_df$num_cluster <- assignCluster(model.matrix(formula_all_dims, EB_df),
                                                 EB_df, 
                                                 cutree(HClust_EB, k = num_clusters_EB))

## pick colour
# library(RColorBrewer)
# EB_cluster_palette <- brewer.pal(n=num_clusters_EB, "Set2")
EB_cluster_palette <- c("blue", "cyan", "darkgray", "green", "violet", "red", "bisque2", "goldenrod2")[1:num_clusters_EB]

recodes_str <- paste0((1:num_clusters_EB), "=", paste0("'", EB_cluster_palette, "'"), collapse = "; ")
require(pander)
require(dplyr)
pander(EB_df %>% dplyr::count(num_cluster), .drop=FALSE)
```

```{r}

EB_cluster_scale_color <- scale_color_manual(name = "Clusters",
                                             breaks = c(1:num_clusters_EB),
                                             values = EB_cluster_palette)

### EB_cluster_fill_color <- scale_fill_manual(breaks = c(1:num_clusters_EB),
###                       values = EB_cluster_palette)



# Funcion que muestra los individuos en un plano factorial con las dimensiones (dimX, dimY) y colorea los clusters
gg_space_cluster <- function(dimX = 1, dimY = 2, k.optimo=3, titulo = "") {
  
  # dimX = 1
  # dimY = 2
  # k.optimo <- 6
  # titulo = ""

  # create column name
  C1 <- paste0("Dim", dimX)
  C2 <- paste0("Dim", dimY)

  figura <- ggplot(data=EB_df, aes(x=.data[[C1]], y=.data[[C2]], color=num_cluster)) +
    geom_point() + geom_rug() +
    geom_vline(xintercept = 0) + geom_hline(yintercept = 0) +
    geom_text_repel(aes(label=rownames(EB_df)),hjust=0, vjust=0, size=3.3) +
    EB_cluster_scale_color +
    #geom_text(aes(label=rownames(EB_df)),hjust=0, vjust=0, size=3.3) +
    theme(legend.position="top") + ggtitle(titulo)
  
  return(figura)
}
```



```{r plot_clusters02}
# Se crea el texto que se mostrara con la figura
# Distribución de los vehículos en cada cluster:
distrib_clusters_EB <-  summary(as.factor(cutree(HClust_EB, k = num_clusters_EB)))
txt_distrib_clusters_EB <- paste0((1:length(distrib_clusters_EB)), ":", distrib_clusters_EB, collapse = ", ")
txt_distrib_clusters_EB_rev <- paste0((length(distrib_clusters_EB):1), ":", rev(distrib_clusters_EB), collapse = ", ")

txt_distrib_clusters_EB_colors <- paste0((1:length(distrib_clusters_EB)), ":", EB_cluster_palette, collapse = ", ")


# Dendograma
#
# TODO: poner una legend en el dendograma para mostrar numero de cluster y sus color
#
require(factoextra)
fviz_dendograma_ACM <- fviz_dend(HClust_EB, 
                               k = num_clusters_EB, 
                               # k_colors = EB_cluster_palette,
                               k_colors = rev(EB_cluster_palette), # reverse colors!!!!
                               rect = TRUE, 
                               show_labels = TRUE, 
                               # main = "Cluster Dendrograma para individuos cercanos a EQUO Berdeak", 
                               main = txt_distrib_clusters_EB_rev, 
                               sub = txt_distrib_clusters_EB)
```




```{r}
require(pander)
pander(distrib_clusters_EB, caption = "Distribución de los cluster")
```

```{r}
fviz_dendograma_ACM
```

```{r}
for (i in seq(numDims_to_show-1)) {
  print(gg_space_cluster(dimX = i, dimY = i+1, k.optimo = num_clusters_EB, titulo = "Clusters de individuos cercanos a EQUO Berdeak"))
}
```

### Caracteristicas de cada cluster de *EQUO Berdeak*

Variabilidad de variables categóricas

https://en.wikipedia.org/wiki/Categorical_distribution

https://stats.stackexchange.com/questions/221332/variance-of-a-distribution-of-multi-level-categorical-data

https://www.cienciasinseso.com/medidas-de-dispersion-cualitativas/

https://cran.r-project.org/web/packages/diverse/diverse.pdf

https://cran.r-project.org/web/packages/qualvar/vignettes/wilcox1973.html


Queremos saber qué tienen en común los individuos de cada cluster. Para ello se analizan y se buscan  las respuestas que más se repiten dentro de cada cluster. dicho en términos matemáticos: se buscan las respuestas con menor entropía.


Hay diferentes formas de medir la diversidad o entropía (https://diposit.ub.edu/dspace/bitstream/2445/45784/1/623311.pdf), pero existe correlación entre todas ellas (https://cran.r-project.org/web/packages/diverse/diverse.pdf): Con estas se cuantifican la *separación*, *variedad* y *disparidad*:

Vamos a utilizar dos índices que son parecidos entre sí. hay que normalizarlos para que no dependan del número de categorías ni del número de individuos de cada cluster. Para ello hay que dividir entre el máximo valor de cada variable. Sabiendo que $k$ es el número de categorías de una variable y que $n$ es el número de individuos de un cluster:
  
  - Índice de Gini-Simpson (también llamado índice de Blau).
  $$B_{max}=\frac{k-1}{k}$$
  - Entropía o índice de Techman
  $$H_{max}=\ln{k}$$


```{r normalized_variety_calculation_EB}
require(diverse)
# Dataframe with 3 calculations
EB_normal_results_df <- data.frame(matrix(ncol = 5, nrow = 0))
colnames(EB_normal_results_df) <- c("n_cluster", "variable", "variety", "blau.index", "entropy")

for (i in seq(num_clusters_EB)) {
  # Select every row = individuals from this cluster i
  aux_idx <- which(EB_df$num_cluster == i)
  # Select every column (= variable) of this cluster
  aux_tbl_cluster <- EB_df[aux_idx,]
  
  # Calculate diversity or entropy of every column
  for (j in  included_cols) {
    k_categories <- nlevels(EB_df[,j])
    b_max <- (k_categories-1)/k_categories
    h_max <- log(k_categories)
    
    # Create contingency table of one variable
    # aux_tbl_var <- base::table(aux_tbl_cluster[,j], useNA = "ifany")
    aux_tbl_var <- base::table(aux_tbl_cluster[,j], useNA = "no")
    # Create three columns dataframe with contingency table
    aux_tbl_var_df <- as.data.frame(rep(j, dim(aux_tbl_var)))
    aux_tbl_var_df[,c(2,3)] <- as.data.frame(aux_tbl_var)
    # colnames(aux_tbl_var_df) <- c("entity", "category", "value")
    
    #Calculation of diversity indexes
    EB_normal_results_df[nrow(EB_normal_results_df)+1, ] <- cbind(i, j, diverse::diversity(aux_tbl_var_df, type =c("variety", "blau", "entropy")))
    # Normalize indexes
    EB_normal_results_df$blau.index[nrow(EB_normal_results_df)] <- EB_normal_results_df$blau.index[nrow(EB_normal_results_df)]/b_max
    EB_normal_results_df$entropy[nrow(EB_normal_results_df)] <- EB_normal_results_df$entropy[nrow(EB_normal_results_df)]/h_max
  }
}
```



```{r cluster_var_tables_EB, echo=FALSE, results='asis'}

# TODO: MOSTRAR ATRIBUTOS PARA TODAS LAS TABLAS: grep(var, pattern = 'P(0-9)')


# Show section with comments an tables by program
#
# Mostrar los resultados de todos los clusters de manera automatizada, por programa
#
# illustrative_vars
EB_vars_not2see <- c("IA_APLAZADA", "IA_MODIFICADA", "IA_SUPERVISADA", "IA_C2_GRUPO")

for (n in 1:num_clusters_EB) {
  # Section title
  cat("#### Cluster", n, "\n\n")
  
  cat(paste("\nEl cluster número", n, "contiene", length(which(EB_df$num_cluster == n)), "individuos.\n"))
  
  # Select every column (= variable) of this cluster n
  aux_tbl_indiv_clust_n <- EB_df[which(EB_df$num_cluster == n),]
  require(pander)
  panderOptions('knitr.auto.asis', FALSE)
  # pander tries to return a knit_asis class object when run inside knitr, but for loops/vectorized functions this results in incorrect output. The recommended way to solve this is to disable this behavior by setting knitr.auto.asis to FALSE using panderOptions. However, we also need to tell knitr to convert the table on the fly by specifying results='asis' in the chunk options
  
  # Show contingency table with RVAUTO20_RECODE
  require(dplyr)
  str_aux_2 <- paste0("Cluster ", n, ". Votos en 2020 `")
  pander(aux_tbl_indiv_clust_n %>% dplyr::count(RVAUTO20_RECODE, .drop=FALSE), caption = str_aux_2)
  
  
  ### require(ggplot2)
  ### aux_tbl <- aux_tbl_indiv_clust_n %>% dplyr::count(EDAD_GRUPO, RVAUTO20_RECODE, .drop=FALSE)
  ### # Stacked barplot with multiple groups
  ### print(ggplot(data=aux_tbl, aes(x=EDAD_GRUPO, y=n, fill=RVAUTO20_RECODE)) +
  ###   geom_bar(stat="identity") +
  ###   scale_fill_manual_RVAUTO20_RECODE) + 
  ###   theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
  
  cat("\n\n**Atributos más importantes de este cluster.**\n")
  
  # Subset every row=variable with their entropy of this cluster, n, excluding those with 0 variety
  aux_tbl_vars_clust_n <- subset(EB_normal_results_df, n_cluster == n & variety !=0)
  # Sort them firstly by entropy and seconly by blau.index
  aux_tbl_vars_clust_n_entrop_sorted <- dplyr::arrange(aux_tbl_vars_clust_n, entropy, blau.index)
  
    
  aux_idx <- aux_tbl_vars_clust_n_entrop_sorted[which(aux_tbl_vars_clust_n_entrop_sorted$entropy < 0.6), "variable"]
  aux_idx <- aux_idx[!(aux_idx %in% EB_vars_not2see)]
  for (k in aux_idx) {
    str_aux_1 <- gsub(pattern = "_GRUPO", replacement = "", k)
    str_aux_2 <- paste0("Cluster ", n, 
                        ". Variable `", k, 
                        "`. ", attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) == str_aux_1],
                        ". Entropía = ", round(aux_tbl_vars_clust_n_entrop_sorted$entropy[which(aux_idx == k)], digits = 4) )
    pander(aux_tbl_indiv_clust_n %>% dplyr::count(.data[[k]], .drop=FALSE), caption = str_aux_2)
  }
}
```

Atributos más importantes de este cluster


## k-vecinos de *EQUO Berdeak*

RANN: Fast Nearest Neighbour Search (Wraps ANN Library) Using L2 Metric

```{r}
require(RANN)
# Save individuals coordinates
space_individuals_df <- cis_2020_acm_df[, c(paste0("Dim", 1:numDim))]

# Select individuals from "Berdeak" or "Otro partido" and create dataframe with that group
space_EB_df <- space_individuals_df[EB_rows,]
# Nearest Neighbour Search
EB_neighb_lst <- RANN::nn2(data = space_individuals_df, query = space_EB_df, k = 10)

# Put those groups in a vector
EB_neighb_idx <- c()
for(i in EB_neighb_lst$nn.idx) {
  EB_neighb_idx <- c(EB_neighb_idx, i)
}
EB_neighb_idx <- unique(EB_neighb_idx)
# Select only neighbours
EB_neighb_idx <- EB_neighb_idx[!(EB_neighb_idx %in% EB_rows)]
# Create column with neighbours
# levels(cis_2020_acm_df$RVAUTO20_RECODE)
cis_2020_acm_df$P20_NEIGH <- cis_2020_acm_df$RVAUTO20_RECODE

# Create new neighbours level
aux_idx <- which(levels(cis_2020_acm_df$P20_NEIGH) == 'EQUO Berdeak')

cis_2020_acm_df$P20_NEIGH <- factor(cis_2020_acm_df$P20_NEIGH, 
                                    levels = c(levels(cis_2020_acm_df$P20_NEIGH)[1:(aux_idx)],
                                                   neighbours_lbl,
                                                   levels(cis_2020_acm_df$P20_NEIGH)[-(1:aux_idx)]))

pander(cis_2020_acm_df %>% dplyr::count(P20_NEIGH), .drop=FALSE, caption = "Votos en 2020")

# Rename neighbours
cis_2020_acm_df$P20_NEIGH[EB_neighb_idx] <- neighbours_lbl

pander(cis_2020_acm_df %>% dplyr::count(P20_NEIGH, .drop=FALSE), caption = "Votos en 2020 y vecinos cercanos a EQUO Berdeak")
```

```{r}
# Plot selected points a its neighbours
gg_plot_neighbours <- function(dimX = 1, dimY = 2){

  my_title <- "Individuos Cercanos a Equo-Berdeak en 2020"
  row_coord_df <- cbind.data.frame(cis_2020_acm_df[,paste0("Dim",dimX)],
                                 cis_2020_acm_df[,paste0("Dim",dimY)],
                                 rownames(cis_2020_acm_df),
                                 cis_2020_acm_df$P20_NEIGH)
  
  colnames(row_coord_df) <- c("dimX", "dimY", "name", "P20_NEIGH")

  require(ggplot2)
  require(ggrepel)
  # Se crea el objeto con el grafico
  gg_obj <- ggplot(row_coord_df, aes(x=dimX, y=dimY, color=P20_NEIGH)) +
    geom_point() + geom_rug() +
    # xlim(-2.6, 3.5) + ylim(-2.1,3.8)+
    geom_text_repel(aes(label=name),hjust=0, vjust=0,size=3.3, max.overlaps = 20) +
    # scale_colour_brewer(palette = "Set1") +
    geom_vline(xintercept = 0) + geom_hline(yintercept = 0) + 
    ggtitle(my_title) +
    xlab(paste("Dimension ", dimX, " (", round(100 * cis_2020_ca_opi01$inertia.e[dimX], digits = 1) , "% )", sep = "")) +
    ylab(paste("Dimension ", dimY, " (", round(100 * cis_2020_ca_opi01$inertia.e[dimY], digits = 1) , "% )", sep = "")) +
    # levels(cis_2020_acm_df$P20_NEIGH)
    scale_color_manual_P20_NEIGH
  
  return(gg_obj)
}
```

Se muestran a todos los vecinos de *EQUO Berdeak* en diferentes planos factoriales.

```{r plot_neigbours}
for (i in seq(numDims_to_show-1)) {
  print(gg_plot_neighbours(dimX = i, dimY = i+1))
}
```


## Decidir el número de cluster y caracterizar estos cluster.

Se toman a todas las personas que dicen haber votado a "EQUO Berdeak" y a todos sus vecinos más cercanos. 
```{r}
# Save EB individuals and there neigbours
EB_neighbourhood_df <- cis_2020_acm_df[c(EB_rows, EB_neighb_idx),]
```

Se muestra la división cluster por el método *Ward.D* o también conocido como *"pérdida de inercia mínima"*.

```{r}
# lista_mtdos <- c("ward.D", "ward.D2", "complete", "single", "average", "mcquitty", "median", "centroid")
mtdo_usado <- "ward.D2" # "ward.D"
formula_all_dims <- as.formula(paste("~-1 +", paste0("Dim",1:numDim, collapse = "+")))
# Distancia euclidea al cuadrado entre los elementos de la matriz
dist_indiv_neigh_EB <- stats::dist(model.matrix(formula_all_dims, EB_neighbourhood_df))^2
HClust_neigh_EB <- hclust(dist_indiv_neigh_EB , method= mtdo_usado)

### plot(HClust_neigh_EB, main= "Cluster Dendrograma para individuos cercanos a EQUO Berdeak", xlab= 
###   "Encuestas CIS EQUO", sub=cat("Method=", mtdo_usado, "; Distancia=euclidea al cuadrado"))
```

se puede buscar el número óptimo de clusters (`k`) usando la función `daisy` (Dissimilarity Matrix Calculation) que computa las desigualdades en las distancias entre parejas. En este caso para obtener el número óptimo de clusters y su composición se ha usado la métrica euclídea al cuadrado para computar las distancias.

```{r eval=FALSE}
# Funcion para calcular el k optimo
# Creamos una funcion para calcular la matriz de distancia dos a dos con los grupos
# daisy: Compute all the pairwise dissimilarities (distances) between observations in the data set.
# https://www.rpubs.com/dvallslanaquera/clustering
grpdist <- function(X, metrica="gower"){
  # metrica = "euclidean", "gower"
  # Se carga la libreria "cluster"
  require(cluster)
  gr <- as.data.frame(as.factor(X))
  distgr <- daisy(gr, metrica)
  distgr
  }
```


```{r include=FALSE, eval=FALSE}
# Lista de metodos a testear
lista_mtdos <- c("ward.D", "ward.D2", "complete", "single", "average", "mcquitty", "median", "centroid")
# data frame auxialiar
kt <- data.frame(k=1:nrow(EB_neighbourhood_df), r=0)

# Bucle para testear todos los metodos con la distancia elegida
for (mtdo_usado in lista_mtdos)
{
  HClust_aux <- hclust(dist_individuos , method= mtdo_usado)

  # plot(HClust_aux, main= "Cluster Dendrograma para coches", xlab= "Vehículos estudiados",sub=paste("Metodo=", mtdo_usado,"; Distancia=euclidea al cuadrado", sep = ""))

  for(i in 2:(nrow(EB_neighbourhood_df)-1)){
    gr <- cutree(HClust_aux, i)
    distgr <- grpdist(gr, "gower")
    mt <- cor(dist_individuos, distgr, method="pearson")
    kt[i,2] <- mt
    }
  # Calculamos mediante el estadístico de Mantel el número de clusters óptimo:
  cat('\nMétodo: "', mtdo_usado,'". k óptimo = ',k_best_aux <- which.max(kt$r),'\nComposición de los clusters:\n', sep = "")

  print(summary(as.factor(cutree(HClust_aux, k = k_best_aux))))
}
```


```{r}
# Se genera el cluster optimo y se representa en el plano
require(gridExtra)
require(grid)
require(ggplot2)
require(lattice)

# La matriz dist_indiv_neigh_EB contiene las distancias euclideas al cuadrado.

require(cluster)

# data frame auxiliar
kt <- data.frame(k=1:nrow(EB_neighbourhood_df), r=0)

# Se elige el numero de clusters optimo
for(i in 2:(nrow(EB_neighbourhood_df)-1)){
  gr <- cutree(HClust_neigh_EB, i)
  distgr <- grpdist(gr, "gower")
  mt <- cor(dist_indiv_neigh_EB, distgr, method="pearson")
  kt[i,2] <- mt
}

num_clusters_acm <- which.max(kt$r)
num_clusters_acm <- num_clusters_acm + 1 ### ATENCION CAMBIAR

# Se crea una columna con el numero de cluster asignado a ese individuo
require(RcmdrMisc)
EB_neighbourhood_df$num_cluster <- assignCluster(model.matrix(formula_all_dims, EB_neighbourhood_df),
                                                 EB_neighbourhood_df, 
                                                 cutree(HClust_neigh_EB, k = num_clusters_acm))

## pick colour
# library(RColorBrewer)
# EB_cluster_palette <- brewer.pal(n=num_clusters_acm, "Set2")
EB_cluster_palette <- c("blue", "cyan", "darkgray", "green", "violet", "red", "bisque2", "goldenrod2")[1:num_clusters_acm]

recodes_str <- paste0((1:num_clusters_acm), "=", paste0("'", EB_cluster_palette, "'"), collapse = "; ")
require(pander)
pander(EB_neighbourhood_df %>% dplyr::count(num_cluster), .drop=FALSE)
```




```{r}

EB_cluster_scale_color <- scale_color_manual(name = "Clusters",
                                             breaks = c(1:num_clusters_acm),
                                             values = EB_cluster_palette)

### EB_cluster_fill_color <- scale_fill_manual(breaks = c(1:num_clusters_acm),
###                       values = EB_cluster_palette)



# Funcion que muestra los individuos en un plano factorial con las dimensiones (dimX, dimY) y colorea los clusters
gg_space_cluster <- function(dimX = 1, dimY = 2, k.optimo=3, titulo = "") {
  
  # dimX = 1
  # dimY = 2
  # k.optimo <- 6
  # titulo = ""

  # create column name
  C1 <- paste0("Dim", dimX)
  C2 <- paste0("Dim", dimY)

  figura <- ggplot(data=EB_neighbourhood_df, aes(x=.data[[C1]], y=.data[[C2]], color=num_cluster)) +
    geom_point() + geom_rug() +
    geom_vline(xintercept = 0) + geom_hline(yintercept = 0) +
    geom_text_repel(aes(label=rownames(EB_neighbourhood_df)),hjust=0, vjust=0, size=3.3) +
    EB_cluster_scale_color +
    #geom_text(aes(label=rownames(EB_neighbourhood_df)),hjust=0, vjust=0, size=3.3) +
    theme(legend.position="top") + ggtitle(titulo)
  
  return(figura)
}
```



```{r plot_clusters03}
# Se crea el texto que se mostrara con la figura
# Distribución de los vehículos en cada cluster:
distrib_clusters_neighbourhood <-  summary(as.factor(cutree(HClust_neigh_EB, k = num_clusters_acm)))
txt_distrib_clusters_neighbourhood <- paste0((1:length(distrib_clusters_neighbourhood)), ":", distrib_clusters_neighbourhood, collapse = ", ")
txt_distrib_clusters_neighbourhood_rev <- paste0((length(distrib_clusters_neighbourhood):1), ":", rev(distrib_clusters_neighbourhood), collapse = ", ")

txt_distrib_clusters_neighbourhood_colors <- paste0((1:length(distrib_clusters_neighbourhood)), ":", EB_cluster_palette, collapse = ", ")


# Dendograma
#
# TODO: poner una legend en el dendograma para mostrar numero de cluster y sus color
#
require(factoextra)
fviz_dendograma_ACM <- fviz_dend(HClust_neigh_EB, 
                               k = num_clusters_acm, 
                               # k_colors = EB_cluster_palette,
                               k_colors = rev(EB_cluster_palette), # reverse colors!!!!
                               rect = TRUE, 
                               show_labels = TRUE, 
                               # main = "Cluster Dendrograma para individuos cercanos a EQUO Berdeak", 
                               main = txt_distrib_clusters_neighbourhood_rev, 
                               sub = txt_distrib_clusters_neighbourhood)
```




```{r}
require(pander)
pander(distrib_clusters_neighbourhood, caption = "Distribución de los cluster")
```

```{r}
fviz_dendograma_ACM
```

```{r}
for (i in seq(numDims_to_show-1)) {
  print(gg_space_cluster(dimX = i, dimY = i+1, k.optimo = num_clusters_acm, titulo = "Clusters de individuos cercanos a EQUO Berdeak"))
}
```

Queremos saber qué tienen en común los individuos de cada cluster. Para ello se analizan y se buscan  las respuestas que más se repiten dentro de cada cluster. dicho en términos matemáticos: se buscan las respuestas con menor entropía.


```{r entropy_calculation, eval=FALSE, echo=FALSE}
require(diverse)
# We need the name of the columns generated by diverse::diversity()
# str_aux_1 <- colnames(diverse::diversity(pantheon))

EB_neighbourhood_results_df <- data.frame(matrix(ncol = 2 + ncol(diverse::diversity(pantheon)), nrow = 0))
colnames(EB_neighbourhood_results_df) <- c("n_cluster", "variable", colnames(diverse::diversity(pantheon)))

for (i in seq(num_clusters_acm)) {
  # Select every row = individuals from this cluster i
  aux_idx <- which(EB_neighbourhood_df$num_cluster == i)
  # Select every column (= variable) of this cluster
  aux_tbl_cluster <- EB_neighbourhood_df[aux_idx,]
  
  # Calulate diversity or entropy of every column
  for (j in  included_cols) {
    
    # j <- "P14A_11" # included_cols[44]
    
    # Create contingency table of one variable
    aux_tbl_var <- base::table(aux_tbl_cluster[,j], useNA = "no")
    # Create three columns dataframe with contingency table
    aux_tbl_var_df <- as.data.frame(rep(j, dim(aux_tbl_var)))
    aux_tbl_var_df[,c(2,3)] <- as.data.frame(aux_tbl_var)
    # colnames(aux_tbl_var_df) <- c("entity", "category", "value")
    
    EB_neighbourhood_results_df[nrow(EB_neighbourhood_results_df)+1, ] <- cbind(i, j, diverse::diversity(aux_tbl_var_df))
  }
}
```


```{r eval=FALSE, echo=FALSE}
library(corrplot)
require(corrplot)

# corrplot(cor(EB_neighbourhood_results_df[-EB_results_out_idx, c(3:ncol(EB_neighbourhood_results_df))]), type = "upper", method = "number", number.cex = .7, tl.cex = 0.6, tl.col = "black")

# We do not use rows with no elements <==> variety == 0
EB_results_out_idx <- which(EB_neighbourhood_results_df$variety == 0)

aux_idx <- !(colnames(EB_neighbourhood_results_df) %in% c("n_cluster", "variable", "variety", "simpson.R", "evenness"))

corrplot(cor(EB_neighbourhood_results_df[-EB_results_out_idx, aux_idx]), type = "upper", method = "number", number.cex = .7, tl.cex = 0.6, tl.col = "black")
```


```{r normalized_variety_calculation}
require(diverse)
# Dataframe with 3 calculations
EB_neighbourhood_normal_results_df <- data.frame(matrix(ncol = 5, nrow = 0))
colnames(EB_neighbourhood_normal_results_df) <- c("n_cluster", "variable", "variety", "blau.index", "entropy")

for (i in seq(num_clusters_acm)) {
  # Select every row = individuals from this cluster i
  aux_idx <- which(EB_neighbourhood_df$num_cluster == i)
  # Select every column (= variable) of this cluster
  aux_tbl_cluster <- EB_neighbourhood_df[aux_idx,]
  
  # Calculate diversity or entropy of every column
  for (j in  included_cols) {
    k_categories <- nlevels(EB_neighbourhood_df[,j])
    b_max <- (k_categories-1)/k_categories
    h_max <- log(k_categories)
    
    # Create contingency table of one variable
    # aux_tbl_var <- base::table(aux_tbl_cluster[,j], useNA = "ifany")
    aux_tbl_var <- base::table(aux_tbl_cluster[,j], useNA = "no")
    # Create three columns dataframe with contingency table
    aux_tbl_var_df <- as.data.frame(rep(j, dim(aux_tbl_var)))
    aux_tbl_var_df[,c(2,3)] <- as.data.frame(aux_tbl_var)
    # colnames(aux_tbl_var_df) <- c("entity", "category", "value")
    
    #Calculation of diversity indexes
    EB_neighbourhood_normal_results_df[nrow(EB_neighbourhood_normal_results_df)+1, ] <- cbind(i, j, diverse::diversity(aux_tbl_var_df, type =c("variety", "blau", "entropy")))
    # Normalize indexes
    EB_neighbourhood_normal_results_df$blau.index[nrow(EB_neighbourhood_normal_results_df)] <- EB_neighbourhood_normal_results_df$blau.index[nrow(EB_neighbourhood_normal_results_df)]/b_max
    EB_neighbourhood_normal_results_df$entropy[nrow(EB_neighbourhood_normal_results_df)] <- EB_neighbourhood_normal_results_df$entropy[nrow(EB_neighbourhood_normal_results_df)]/h_max
  }
}
```

Se muestra la correlación entre ambos índices:

```{r}
require(corrplot)
# Columns to calculate correlation
aux_idx <- !(colnames(EB_neighbourhood_normal_results_df) %in% c("n_cluster", "variable", "variety"))
# We do not use rows with no elements <==> variety == 0
EB_results_out_idx <- which(EB_neighbourhood_normal_results_df$variety == 0)
if (length(EB_results_out_idx) == 0){
  corrplot(cor(EB_neighbourhood_normal_results_df[, aux_idx]), type = "upper", method = "number", number.cex = 1.7, tl.cex = 1.0, tl.col = "black")
}else{
  corrplot(cor(EB_neighbourhood_normal_results_df[-EB_results_out_idx, aux_idx]), type = "upper", method = "number", number.cex = 1.7, tl.cex = 1.0, tl.col = "black")
}
```



```{r cluster_var_tables, echo=FALSE, results='asis'}

# TODO: MOSTRAR ATRIBUTOS PARA TODAS LAS TABLAS: grep(var, pattern = 'P(0-9)')


# Show section with comments an tables by program
#
# Mostrar los resultados de todos los clusters de manera automatizada, por programa
#
# illustrative_vars
EB_vars_not2see <- c("IA_APLAZADA", "IA_MODIFICADA", "IA_SUPERVISADA", "IA_C2_GRUPO")

for (n in 1:num_clusters_acm) {
  # Section title
  cat("### Cluster", n, "\n\n")
  
  cat(paste("\nEl cluster número", n, "contiene", length(which(EB_neighbourhood_df$num_cluster == n)), "individuos.\n"))
  
  # Select every column (= variable) of this cluster n
  aux_tbl_indiv_clust_n <- EB_neighbourhood_df[which(EB_neighbourhood_df$num_cluster == n),]
  require(pander)
  panderOptions('knitr.auto.asis', FALSE)
  # pander tries to return a knit_asis class object when run inside knitr, but for loops/vectorized functions this results in incorrect output. The recommended way to solve this is to disable this behavior by setting knitr.auto.asis to FALSE using panderOptions. However, we also need to tell knitr to convert the table on the fly by specifying results='asis' in the chunk options
  
  # Show contingency table with RVAUTO20_RECODE
  require(dplyr)
  str_aux_2 <- paste0("Cluster ", n, ". Votos en 2020 `")
  pander(aux_tbl_indiv_clust_n %>% dplyr::count(RVAUTO20_RECODE, .drop=FALSE), caption = str_aux_2)
  
  
  require(ggplot2)
  aux_tbl <- aux_tbl_indiv_clust_n %>% dplyr::count(EDAD_GRUPO, RVAUTO20_RECODE, .drop=FALSE)
  # Stacked barplot with multiple groups
  print(ggplot(data=aux_tbl, aes(x=EDAD_GRUPO, y=n, fill=RVAUTO20_RECODE)) +
    geom_bar(stat="identity") +
    scale_fill_manual_RVAUTO20_RECODE) + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
  
  cat("\n\n**Atributos más importantes de este cluster.**\n")
  
  # Subset every row=variable with their entropy of this cluster, n, excluding those with 0 variety
  aux_tbl_vars_clust_n <- subset(EB_neighbourhood_normal_results_df, n_cluster == n & variety !=0)
  # Sort them firstly by entropy and seconly by blau.index
  aux_tbl_vars_clust_n_entrop_sorted <- dplyr::arrange(aux_tbl_vars_clust_n, entropy, blau.index)
  
    
  aux_idx <- aux_tbl_vars_clust_n_entrop_sorted[which(aux_tbl_vars_clust_n_entrop_sorted$entropy < 0.6), "variable"]
  aux_idx <- aux_idx[!(aux_idx %in% EB_vars_not2see)]
  for (k in aux_idx) {
    str_aux_1 <- gsub(pattern = "_GRUPO", replacement = "", k)
    str_aux_2 <- paste0("Cluster ", n, 
                        ". Variable `", k, 
                        "`. ", attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) == str_aux_1],
                        ". Entropía = ", round(aux_tbl_vars_clust_n_entrop_sorted$entropy[which(aux_idx == k)], digits = 4) )
    pander(aux_tbl_indiv_clust_n %>% dplyr::count(.data[[k]], .drop=FALSE), caption = str_aux_2)
  }
}
```



# Apendices

## Elegir índice de diversidad:

https://diposit.ub.edu/dspace/bitstream/2445/45784/1/623311.pdf

**Variety Indexes**

Diversity as variety conceptualizes categorical differences across the relevant characteristics between group members.
 
 - Blau’s values are not validly comparable if the number of categories is not identical across diversity variables. Nevertheless, researchers have asserted that comparisons between variables with a dissimilar number of categories still make sense, as long as larger number of categories contributes to greater diversity
 $$B_{max} = \frac{k-1}{k}$$
 
 - IQV However, the index B can be normalized by dividing it by its maximum. This controls for the number of categories, and gives the Index of Qualitative Variation (IQV; Agresti & Agresti, 1978). Blau’s index and IQV can be used interchangeably when comparing variables with the same number of categories because they are highly similar measures and only differ in scale. if Blau’s index and IQV are multiplied by $n/(n-1)$, the estimators obtained are unbiased.

**Disparity Indexes**

Diversity as disparity assumes asymmetry and is defined as the difference between group members in terms of the resources each of them
holds. It reflects both the distances between group members and the dominance of those individuals that have higher amounts of the attribute.

 - The coefficient of variation, V, is calculated by dividing the standard deviation by the mean.
 - Gini coefficient, $\Delta$, is a measure of inequality for quantitative variables and it is defined as the average of the absolute differences of all pairs of variate values in a sample, expressed in terms of units of the variate. The coefficient is not suitable for ratio scales, but can be obtained in interval scales.
 - The Gini coefficient of concentration is defined $G$ so $\Delta$ is converted into a scale invariant measure by dividing the coefficient of concentration by twice the arithmetic mean. he coefficient G is only appropriate for attributes measured by ratio scales (Allison, 1978). G has lower and upper bounds, although its maximum value depends on $n$.
 
**Separation Indexes**

Diversity as separation conceptualizes the member’s differences in position or disagreement in opinion toward a global attribute.

 - The widely used measures of diversity as separation are standard deviation (SD) and mean Euclidean distance (D).


## Atributos de cada variable


```{r variables_attrib, echo=FALSE, results='asis'}
preguntas_atributos <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(preguntas_atributos) <- c("Pregunta", "Título")
cat("\n")
for (i in grep(pattern = "_GRUPO|_RECODE", x = colnames(cis_2020_df), value = TRUE, invert = TRUE)) {
  str_aux_2 <- paste0(" \n - ", i, ": ", attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) == i])
  cat(str_aux_2)
  preguntas_atributos[nrow(preguntas_atributos)+1,] <- rbind(i, attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) == i])
}
```



```{r export_EB_entropy2XLS, eval=FALSE}
#Define the file name that will be deleted
EB_entropia_XLS <- "EB_entropia.xlsx"
#Check its existence
if (file.exists(EB_entropia_XLS)) {
  #Delete file if it exists
  if (file.remove(EB_entropia_XLS)){
    log4r::debug(logger_analysis, paste("Fichero:", EB_entropia_XLS, "correctamente eliminado"))
  }else{
    log4r::error(logger_analysis, paste("ERROR: NO SE PUDO ELIMINAR EL FICHERO:", EB_entropia_XLS ))
  }
}else{
  log4r::debug(logger_analysis, paste("Fichero:", EB_entropia_XLS, "no existe"))
}
#
# 1st: Retrive info about EB neighbours
# Get indexes of first cluster
aux_idx <- which(EB_neighbourhood_normal_results_df$n_cluster == 1)
# Create entropy dataframe
neigbours_entropy2XLS_df <- data.frame(matrix(ncol = num_clusters_acm+3, nrow = length(aux_idx)))
colnames(neigbours_entropy2XLS_df) <- c("Pregunta", paste0("Cluster", 1:num_clusters_acm), "Suma entropía", "Título")

# Get variable names
neigbours_entropy2XLS_df$Pregunta <- EB_neighbourhood_normal_results_df$variable[aux_idx]
# Get clusters entropy
for (i in seq(num_clusters_acm)) {
  aux_idx <- which(EB_neighbourhood_normal_results_df$n_cluster == i)
  neigbours_entropy2XLS_df[,1+i] <- EB_neighbourhood_normal_results_df[aux_idx, "entropy"]
}
# sum entropy and get attributes
for (i in seq(nrow(neigbours_entropy2XLS_df))) {
  # Sum entropy
  neigbours_entropy2XLS_df$`Suma entropía`[i] <- sum(neigbours_entropy2XLS_df[i,c(seq(num_clusters_acm)+1)])
  # Get variables attributes
  str_aux_1 <- gsub(pattern = "_GRUPO|_RECODE", replacement = "", x= neigbours_entropy2XLS_df$Pregunta[i])
  neigbours_entropy2XLS_df$Título[i] <- attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) == str_aux_1]
}
#
# 2nd: Retrive info about EB along
# Get indexes of first cluster
aux_idx <- which(EB_normal_results_df$n_cluster == 1)
# Create entropy dataframe
EB_entropy2XLS_df <- data.frame(matrix(ncol = num_clusters_EB+3, nrow = length(aux_idx)))
colnames(EB_entropy2XLS_df) <- c("Pregunta", paste0("Cluster", 1:num_clusters_EB), "Suma entropía", "Título")

# Get variable names
EB_entropy2XLS_df$Pregunta <- EB_normal_results_df$variable[aux_idx]
# Get clusters entropy
for (i in seq(num_clusters_EB)) {
  aux_idx <- which(EB_normal_results_df$n_cluster == i)
  EB_entropy2XLS_df[,1+i] <- EB_normal_results_df[aux_idx, "entropy"]
}
# sum entropy and get attributes
for (i in seq(nrow(EB_entropy2XLS_df))) {
  # Sum entropy
  EB_entropy2XLS_df$`Suma entropía`[i] <- sum(EB_entropy2XLS_df[i,c(seq(num_clusters_EB)+1)])
  # Get variables attributes
  str_aux_1 <- gsub(pattern = "_GRUPO|_RECODE", replacement = "", x= EB_entropy2XLS_df$Pregunta[i])
  EB_entropy2XLS_df$Título[i] <- attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) == str_aux_1]
}

# Save dataframe to an excel file
require(openxlsx)
if (file.exists(EB_entropia_XLS)){
  log4r::error(logger_analysis, paste("Aun existe el fichero", EB_entropia_XLS))
  ### EB_wb <- openxlsx::loadWorkbook(EB_entropia_XLS)
}else{
  log4r::debug(logger_analysis, paste("Fichero:", EB_entropia_XLS, "no existe. OK"))
  ### EB_wb <- openxlsx::createWorkbook()
}
# Create new workbook
EB_wb <- openxlsx::createWorkbook()
#
# 1st: Save neigbours entropy to XLS
# Add sheet entropia
openxlsx::addWorksheet(wb=EB_wb, sheetName = "kVecinos")
openxlsx::writeData(wb=EB_wb, sheet="kVecinos", x=neigbours_entropy2XLS_df)
#
# Add sheet num persons per cluster
aux_tbl <- data.frame(matrix(ncol = 1+num_clusters_acm, nrow = 1))
colnames(aux_tbl) <- c("", paste0("Cluster", 1:num_clusters_acm))
aux_tbl [1,] <- c("Num individuos por cluster", distrib_clusters_neighbourhood)
#
openxlsx::addWorksheet(wb=EB_wb, sheetName = "Num_por_cluster_kVecinos")
openxlsx::writeData(wb=EB_wb, sheet="Num_por_cluster_kVecinos", x=aux_tbl)
#
# Add sheet Entrevistas CIS
aux_tbl <- cbind.data.frame(rownames(EB_neighbourhood_df) ,EB_neighbourhood_df)
colnames(aux_tbl)[1] <- "ID entrevista"
openxlsx::addWorksheet(wb=EB_wb, sheetName = "Entrevistas_kVecinos")
openxlsx::writeData(wb=EB_wb, sheet="Entrevistas_kVecinos", x=aux_tbl)
#
#
# 2st: Save EB entropy to XLS
# Add sheet entropia
openxlsx::addWorksheet(wb=EB_wb, sheetName = "EB")
openxlsx::writeData(wb=EB_wb, sheet="EB", x=EB_entropy2XLS_df)
#
# Add sheet num persons per cluster
aux_tbl <- data.frame(matrix(ncol = 1+num_clusters_EB, nrow = 1))
colnames(aux_tbl) <- c("", paste0("Cluster", 1:num_clusters_EB))
aux_tbl [1,] <- c("Num individuos por cluster", distrib_clusters_EB)
#
openxlsx::addWorksheet(wb=EB_wb, sheetName = "Num_por_cluster_EB")
openxlsx::writeData(wb=EB_wb, sheet="Num_por_cluster_EB", x=aux_tbl)
#
# Add sheet Entrevistas CIS
aux_tbl <- cbind.data.frame(rownames(EB_df) ,EB_df)
colnames(aux_tbl)[1] <- "ID entrevista"
openxlsx::addWorksheet(wb=EB_wb, sheetName = "Entrevistas_EB")
openxlsx::writeData(wb=EB_wb, sheet="Entrevistas_EB", x=aux_tbl)
#
# Add sheet with questions and explanations
openxlsx::addWorksheet(wb=EB_wb, sheetName = "Preguntas")
openxlsx::writeData(wb=EB_wb, sheet="Preguntas", x=preguntas_atributos)


# Save and close workbook
openxlsx::saveWorkbook(wb=EB_wb, EB_entropia_XLS, overwrite = TRUE)

```



```{r export_EB_similarity2XLS}
# Define the file name that will be deleted
EB_similitud_XLS <- "EB_similitud.xlsx"
#Check its existence
if (file.exists(EB_similitud_XLS)) {
  #Delete file if it exists
  if (file.remove(EB_similitud_XLS)){
    log4r::debug(logger_analysis, paste("Fichero:", EB_similitud_XLS, "correctamente eliminado"))
  }else{
    log4r::error(logger_analysis, paste("ERROR: NO SE PUDO ELIMINAR EL FICHERO:", EB_similitud_XLS ))
  }
}else{
  log4r::debug(logger_analysis, paste("Fichero:", EB_similitud_XLS, "no existe"))
}
#
# 1st: Retrive info about EB neighbours
# Get indexes of first cluster
aux_idx <- which(EB_neighbourhood_normal_results_df$n_cluster == 1)
# Create similarity dataframe
neigbours_similarity2XLS_df <- data.frame(matrix(ncol = num_clusters_acm+3, nrow = length(aux_idx)))
colnames(neigbours_similarity2XLS_df) <- c("Pregunta", paste0("Cluster", 1:num_clusters_acm), "Suma similitud", "Título")

# Get variable names
neigbours_similarity2XLS_df$Pregunta <- EB_neighbourhood_normal_results_df$variable[aux_idx]
# Get clusters similarity
for (i in seq(num_clusters_acm)) {
  aux_idx <- which(EB_neighbourhood_normal_results_df$n_cluster == i)
  # We calculate the opposite of entropy => 1 - entropy = similarity
  neigbours_similarity2XLS_df[,1+i] <- 1 - EB_neighbourhood_normal_results_df[aux_idx, "entropy"]
}


# sum similarity and get attributes
for (i in seq(nrow(neigbours_similarity2XLS_df))) {
  # Sum similarity
  neigbours_similarity2XLS_df$`Suma similitud`[i] <- sum(neigbours_similarity2XLS_df[i,c(seq(num_clusters_acm)+1)])
  # Get variables attributes
  str_aux_1 <- gsub(pattern = "_GRUPO|_RECODE", replacement = "", x= neigbours_similarity2XLS_df$Pregunta[i])
  neigbours_similarity2XLS_df$Título[i] <- attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) == str_aux_1]
}
#
# 2nd: Retrive info about EB along
# Get indexes of first cluster
aux_idx <- which(EB_normal_results_df$n_cluster == 1)
# Create similarity dataframe
EB_similarity2XLS_df <- data.frame(matrix(ncol = num_clusters_EB+3, nrow = length(aux_idx)))
colnames(EB_similarity2XLS_df) <- c("Pregunta", paste0("Cluster", 1:num_clusters_EB), "Suma similitud", "Título")

# Get variable names
EB_similarity2XLS_df$Pregunta <- EB_normal_results_df$variable[aux_idx]
# Get clusters similarity
for (i in seq(num_clusters_EB)) {
  aux_idx <- which(EB_normal_results_df$n_cluster == i)
  EB_similarity2XLS_df[,1+i] <- 1 - EB_normal_results_df[aux_idx, "entropy"]
}
# sum similarity and get attributes
for (i in seq(nrow(EB_similarity2XLS_df))) {
  # Sum similarity
  EB_similarity2XLS_df$`Suma similitud`[i] <- sum(EB_similarity2XLS_df[i,c(seq(num_clusters_EB)+1)])
  # Get variables attributes
  str_aux_1 <- gsub(pattern = "_GRUPO|_RECODE", replacement = "", x= EB_similarity2XLS_df$Pregunta[i])
  EB_similarity2XLS_df$Título[i] <- attributes(cis_2020_df)$variable.labels[colnames(cis_2020_df) == str_aux_1]
}

# Save dataframe to an excel file
require(openxlsx)
if (file.exists(EB_similitud_XLS)){
  log4r::error(logger_analysis, paste("Aun existe el fichero", EB_similitud_XLS))
  ### EB_wb <- openxlsx::loadWorkbook(EB_similitud_XLS)
}else{
  log4r::debug(logger_analysis, paste("Fichero:", EB_similitud_XLS, "no existe. OK"))
  ### EB_wb <- openxlsx::createWorkbook()
}
# Create new workbook
EB_wb <- openxlsx::createWorkbook()
#
# 1st: Save neigbours similarity to XLS
# Add sheet similitud
openxlsx::addWorksheet(wb=EB_wb, sheetName = "kVecinos")
openxlsx::writeData(wb=EB_wb, sheet="kVecinos", x=neigbours_similarity2XLS_df)
#
# Add sheet num persons per cluster
aux_tbl <- data.frame(matrix(ncol = 1+num_clusters_acm, nrow = 1))
colnames(aux_tbl) <- c("_", paste0("Cluster", 1:num_clusters_acm))
# If we do:
# aux_tbl [1,] <- c("Num individuos por cluster", distrib_clusters_neighbourhood)
# We get character instead of numeric
aux_tbl [1,1] <- "Num individuos por cluster"
for (i in seq(from = 2, length.out = length(distrib_clusters_neighbourhood))) {
  aux_tbl[1, i] <- distrib_clusters_neighbourhood[i-1]
}
#
openxlsx::addWorksheet(wb=EB_wb, sheetName = "Num_por_cluster_kVecinos")
openxlsx::writeData(wb=EB_wb, sheet="Num_por_cluster_kVecinos", x=aux_tbl)
#
# Add sheet Entrevistas CIS
aux_tbl <- cbind.data.frame(rownames(EB_neighbourhood_df) ,EB_neighbourhood_df)
colnames(aux_tbl)[1] <- "ID entrevista"
openxlsx::addWorksheet(wb=EB_wb, sheetName = "Entrevistas_kVecinos")
openxlsx::writeData(wb=EB_wb, sheet="Entrevistas_kVecinos", x=aux_tbl)
#
#
# 2st: Save EB similarity to XLS
# Add sheet similitud
openxlsx::addWorksheet(wb=EB_wb, sheetName = "EB")
openxlsx::writeData(wb=EB_wb, sheet="EB", x=EB_similarity2XLS_df)
#
# Add sheet num persons per cluster
aux_tbl <- data.frame(matrix(ncol = 1+num_clusters_EB, nrow = 1))
colnames(aux_tbl) <- c("", paste0("Cluster", 1:num_clusters_EB))
# If we do:
# aux_tbl [1,] <- c("Num individuos por cluster", distrib_clusters_EB)
# We get character instead of numeric
aux_tbl [1,1] <- "Num individuos por cluster"
for (i in seq(from = 2, length.out = length(distrib_clusters_EB))) {
  aux_tbl[1, i] <- distrib_clusters_EB[i-1]
}
#
openxlsx::addWorksheet(wb=EB_wb, sheetName = "Num_por_cluster_EB")
openxlsx::writeData(wb=EB_wb, sheet="Num_por_cluster_EB", x=aux_tbl)
#
# Add sheet Entrevistas CIS
aux_tbl <- cbind.data.frame(rownames(EB_df) ,EB_df)
colnames(aux_tbl)[1] <- "ID entrevista"
openxlsx::addWorksheet(wb=EB_wb, sheetName = "Entrevistas_EB")
openxlsx::writeData(wb=EB_wb, sheet="Entrevistas_EB", x=aux_tbl)
#
# Add sheet with questions and explanations
openxlsx::addWorksheet(wb=EB_wb, sheetName = "Preguntas")
openxlsx::writeData(wb=EB_wb, sheet="Preguntas", x=preguntas_atributos)


# Save and close workbook
openxlsx::saveWorkbook(wb=EB_wb, EB_similitud_XLS, overwrite = TRUE)

```




***

\pagebreak



```{r save_variables}
# Save data variables to cis_2020_analisys_file.RData
# cis_2020_analisys_file <- file.path(getwd(), "data", "cis_2020_analisys_file.RData")
cis_2020_analisys_file <- file.path(getwd(), "cis_2020_analisys_file.RData")

require(log4r)
log4r::info(logger_analysis, paste("cis_2020_analisys_file (", cis_2020_analisys_file, ") exists =", file.exists(cis_2020_analisys_file)))

# Save every data in an RData file.
# It will be used later in the Rmd file.
# save(list = ls(), file=cis_2020_analisys_file)
save(list = grep(pattern = "aux", x = ls(), value = TRUE, invert = TRUE), file=cis_2020_analisys_file)

log4r::info(logger_analysis, paste("Saved cis_2020_analisys_file dataset"))
info(logger_analysis, 'Ending script')
```

---
